<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" >

<head>
    <style type="text/css">
        h1 {
            margin-top: 0;
            margin-bottom: 0;
        }
        td {
            padding-bottom: 1em;
        }
    </style>
    <title>Fabio Pardo</title>
</head>
<body>

<center>
<table>
    <td style="width: 1000px" valign=top align=left>
    <table cellpadding=5px>
        <td valign=top>
            <img src="images/fabio_portrait.jpg" alt="Fabio Pardo" height="300" border=0/>
        </td>
        <td align=left valign=top width=100% style="padding-left:20px;>
            <a id="top"></a>
            <h1>Fabio Pardo</h1><br>
                PhD Student in Machine Learning<br>
               <br>
                Imperial College London<br>
                London, SW7 1NA<br>
                United Kingdom<br>
               <br>
                <code>f.pardo[at]imperial.ac.uk</code><br>
               <br>
                <a href="https://github.com/fabiopardo"><img src="images/github.svg" alt="fabiopardo" height="50"/></a>
                <a href="https://twitter.com/pardofab"><img src="images/twitter.svg" alt="@pardofab" height="50"/></a>
        </td>
    </table>

<p align=justify>
    I am a fourth-year PhD student in the
    <a href="https://www.imperial.ac.uk/robot-intelligence/">Robot Intelligence Lab</a> at
    <a href="https://www.imperial.ac.uk/">Imperial College London</a>.<br>
    My main research focuses on Deep Reinforcement Learning.
</p>

<body>
    <div class="row">
        <h2>Education</h2>
        <table>
            <tr>
                <td valign="top" width="350">
                    <img src="images/imperial.png" height="50"/>
                </td>
                <td valign="top">
                    <b>2016 – present</b><br>
                    PhD in <b>Machine Learning</b><br>
                    Deep Reinforcement Learning<br>
                    @ Imperial College, London, UK
                </td>
            </tr>
            <tr>
                <td valign="top">
                    <img src="images/upmc.png" height="35"/>
                </td>
                <td valign="top">
                    <b>2014 – 2015</b><br>
                    Master's degree in <b>Computer Science</b><br>
                    AI, ML, Robotics<br>
                    @ Pierre et Marie Curie University, Paris, France
                </td>
            </tr>
            <tr>
                <td valign="top">
                    <img src="images/ens.png" height="50" valign="top"/>
                    <img src="images/ehess.png" height="50" valign="top"/>
                    <img src="images/descartes.png" height="50" valign="top"/>
                </td>
                <td valign="top">
                    <b>2012 – 2014</b><br>
                    Master’s degree in <b>Cognitive Science</b><br>
                    Neuroscience, Cognitive Psychology, Computational Modeling, Neuroimaging, AI<br>
                    @ École Normale Supérieure Ulm, EHESS and Descartes University, Paris, France
                </td>
            </tr>
            <tr>
                <td valign="top">
                    <img src="images/upmc.png" height="35"/>
                </td>
                <td valign="top">
                    <b>2009 – 2012</b><br>
                    Bachelor's degree in <b>Computer Science</b><br>
                    @ Pierre et Marie Curie University, Paris, France
                </td>
            </tr>
        </table>
    </div>

    <div class="row">
        <h2>Research Internships</h2>
        <table>
            <tr>
                <td valign="top" width="350">
                    <img src="images/deepmind.png" height="40"/>
                </td>
                <td valign="top">
                    <b>2019</b><br>
                    <b>Motor primitives and competitive self-play</b><br>
                    Raia Hadsell, Nicolas Heess, Josh Merel and Leonard Hasenclever<br>
                    @ DeepMind, London, UK
                </td>
            </tr>

            <tr>
                <td valign="top" width="350">
                    <img src="images/nii.png" height="30"/>
                </td>
                <td valign="top">
                    <b>2015</b><br>
                    <b>Deep reinforcement learning for autonomous robot navigation from vision</b><br>
                    Tetsunari Inamura<br>
                    @ National Institute of Informatics, Tokyo, Japan
                </td>
            </tr>

            <tr>
                <td valign="top" width="350">
                    <img src="images/flowers.png" height="32"/>
                </td>
                <td valign="top">
                    <b>2014</b><br>
                    <b>Multimodal concepts emergence for a humanoid robot in interaction with a human tutor</b><br>
                    David Filliat<br>
                    @ Flowers laboratory, Inria and ENSTA ParisTech, Paris, France
                </td>
            </tr>

            <tr>
                <td valign="top" width="350">
                    <img src="images/inria.png" height="30"/>
                </td>
                <td valign="top">
                    <b>2013</b><br>
                    <b>Optimal decision making based on a mixture of prediction experts</b><br>
                    <b>Homeostatic engine for reinforcement learning agents</b><br>
                    Laurent Orseau<br>
                    @ Inria and AgroParisTech, Paris, France
                </td>
            </tr>

            <tr>
                <td valign="top" width="350">
                    <img src="images/lip6.png" height="50"/>
                </td>
                <td valign="top">
                    <b>2013</b><br>
                    <b>Ontology visualization methods and their impact on short-term memory storage in humans</b><br>
                    Jean-Gabriel Ganascia<br>
                    @ Lip6, Paris, France
                </td>
            </tr>
        </table>
    </div>

    <div class="row">
        <h2>Publications</h2>
        <table>
            <tr>
                <td valign="top" width="350">
                    <img src="images/comic.gif" height="100"/>
                </td>
                <td valign="top">
                    <b>CoMic: Complementary Task Learning & Mimicry for Reusable Skills</b><br>
                    Leonard Hasenclever, Fabio Pardo, Raia Hadsell, Nicolas Heess, Josh Merel<br>
                    @ ICML 2020<br>
                    <a href="https://proceedings.icml.cc/static/paper_files/icml/2020/5013-Paper.pdf">Paper</a> and
                    <a href="https://github.com/deepmind/dm_control/tree/master/dm_control/locomotion/tasks/reference_pose">code</a>
                </td>
            </tr>

            <tr>
                <td valign="top" width="350">
                    <img src="images/qmap_mario_montezuma.gif" height="200"/>
                </td>
                <td valign="top">
                    <b>Scaling All-Goals Updates in Reinforcement Learning Using Convolutional Neural Networks</b><br>
                    Fabio Pardo, Vitaly Levdik, Petar Kormushev<br>
                    @ AAAI 2020<br>
                    @ NeurIPS 2018 Deep RL Workshop<br>
                    @ ICML 2018 Exploration in RL Workshop<br>
                    <a href="https://arxiv.org/abs/1810.02927">Paper</a>,
                    <a href="posters/qmap.pdf">poster</a>,
                    <a href="https://sites.google.com/view/q-map-rl">website</a> and
                    <a href="https://github.com/fabiopardo/qmap">code</a>
                </td>
            </tr>

            <tr>
                <td valign="top" width="350">
                    <img src="images/time-limited_Hopper.gif" height="100"/>
                    <img src="images/time-unlimited_Hopper.gif" height="100"/>
                </td>
                <td valign="top">
                    <b>Time Limits in Reinforcement Learning</b><br>
                    Fabio Pardo, Arash Tavakoli, Vitaly Levdik, Petar Kormushev<br>
                    @ ICML 2018<br>
                    @ NIPS 2017 Deep RL Symposium<br>
                    <a href="https://arxiv.org/abs/1712.00378">Paper</a>,
                    <a href="posters/time_limits_in_rl.pdf">poster</a> and
                    <a href="https://sites.google.com/view/time-limits-in-rl">website</a>
                </td>
            </tr>

            <tr>
                <td valign="top" width="350">
                    <img src="images/branching.png" height="80"/>
                </td>
                <td valign="top">
                    <b>Action Branching Architectures for Deep Reinforcement Learning</b><br>
                    Arash Tavakoli, Fabio Pardo, Petar Kormushev<br>
                    @ AAAI 2018<br>
                    @ NIPS 2017 Deep RL Symposium<br>
                    <a href="https://arxiv.org/abs/1711.08946">Paper</a> and
                    <a href="posters/action_branching_architectures.pdf">poster</a>
                </td>
            </tr>
        </table>
    </div>

    <div class="row">
        <h2>Softwares</h2>
        <table>
            <tr>
                <td valign="top" width="350">
                    <img src="images/tonic.png" height="70"/><br><br>
                    <img src="images/tonic.gif" height="100"/>
                </td>
                <td valign="top">
                    <b>Tonic: A Deep Reinforcement Learning Library for Fast Prototyping and Benchmarking</b><br>
                    <ul>
                        <li>a collection of configurable modules such as: exploration strategies, memories, neural networks, and optimizers</li>
                        <li>a collection of baseline agents built with these modules</li>
                        <li>support for the two most popular deep learning frameworks: TensorFlow and PyTorch</li>
                        <li>support for the three most popular sets of continuous control environments: OpenAI Gym, DeepMind Control Suite and PyBullet</li>
                        <li>a large-scale benchmark of the baseline agents on 70 tasks</li>
                        <li>scripts to train in a reproducible way, plot results, and play with trained agents.</li>
                    </ul>
                    <a href="https://github.com/fabiopardo/tonic">Repository</a> and
                    <a href="https://github.com/fabiopardo/tonic_data">data</a>
                </td>
            </tr>
        </table>
    </div>

    <div class="row">
        <h2>Miscellaneous</h2>
        <table>
            <tr>
                <td valign="top" width="350">
                    <img src="images/imperial.png" height="50"/>
                </td>
                <td valign="top">
                    <b>2016 – present</b><br>
                    Graduate teaching assistant<br>
                    Computing and Robotics<br>
                    @ Imperial College, London, UK
                </td>
            </tr>

            <tr>
                <td valign="top" width="350">
                    <img src="images/prologin.png" height="60"/>
                </td>
                <td valign="top">
                    <b>2011 and 2012</b><br>
                    Twice finalist of Prologin, the French national programming contest<br>
                    Algorithmic tests and 36-hour hackathon<br>
                    @ École Polytechnique and EPITA, Paris, France
                </td>
            </tr>
        </table>
    </div>
</body>
</html>
