<!DOCTYPE html>
<html>
    <head>
        <title>Fabio Pardo</title>
    </head>

    <style>
        h1 {
            margin-top: 0;
            margin-bottom: 0;
        }
        div {
            max-width: 960px;
            margin: auto;
        }
        td {
            valign: top;
            padding-bottom: 1em;
        }
        ul {
            margin-top: 0;
            margin-bottom: 0;
            padding-left: 1em;
        }
    </style>

    <body>
        <div>
            <table>
                <td width="230">
                    <img src="images/fabio_portrait.jpg" alt="Fabio Pardo" height="250"/>
                </td>
                <td>
                    <h1>Fabio Pardo</h1>
                    <br>
                    PhD Student in Machine Learning<br>
                    <br>
                    Imperial College London<br>
                    London, SW7 1NA<br>
                    United Kingdom<br>
                    <br>
                    <code>f.pardo[at]imperial.ac.uk</code><br>
                    <br>
                    <a href="https://github.com/fabiopardo"><img src="images/github.svg" alt="fabiopardo" height="50"/></a>
                    <a href="https://twitter.com/pardofab"><img src="images/twitter.svg" alt="@pardofab" height="50"/></a>
                </td>
            </table>
        </div>

        <div>
            <br>
            I am a fourth-year PhD student in the
            <a href="https://www.imperial.ac.uk/robot-intelligence/">Robot Intelligence Lab</a> at
            <a href="https://www.imperial.ac.uk/">Imperial College London</a>.<br>
            My main research focuses on Deep Reinforcement Learning.<br><br>
        </div>

        <div>
            <h2>Education</h2>
            <table>
                <tr>
                    <td width="350">
                        <img src="images/imperial.png" height="50"/>
                    </td>
                    <td>
                        <b>2016 – present</b><br>
                        PhD in <b>Machine Learning</b><br>
                        Deep Reinforcement Learning<br>
                        @ Imperial College, London, UK
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/upmc.png" height="35"/>
                    </td>
                    <td>
                        <b>2014 – 2015</b><br>
                        Master's degree in <b>Computer Science</b><br>
                        AI, ML, Robotics<br>
                        @ Pierre et Marie Curie University, Paris, France
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/ens.png" height="50"/>
                        <img src="images/ehess.png" height="50"/>
                        <img src="images/descartes.png" height="50"/>
                    </td>
                    <td>
                        <b>2012 – 2014</b><br>
                        Master’s degree in <b>Cognitive Science</b><br>
                        Neuroscience, Cognitive Psychology, Computational Modeling, Neuroimaging, AI<br>
                        @ École Normale Supérieure Ulm, EHESS and Descartes University, Paris, France
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/upmc.png" height="35"/>
                    </td>
                    <td>
                        <b>2009 – 2012</b><br>
                        Bachelor's degree in <b>Computer Science</b><br>
                        @ Pierre et Marie Curie University, Paris, France
                    </td>
                </tr>
            </table>
        </div>

        <div>
            <h2>Research Internships</h2>
            <table>
                <tr>
                    <td width="350">
                        <img src="images/deepmind.png" height="40"/>
                    </td>
                    <td>
                        <b>2019</b><br>
                        <b>Motor primitives and competitive self-play</b><br>
                        Raia Hadsell, Nicolas Heess, Josh Merel and Leonard Hasenclever<br>
                        @ DeepMind, London, UK
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/nii.png" height="30"/>
                    </td>
                    <td>
                        <b>2015</b><br>
                        <b>Deep reinforcement learning for autonomous robot navigation from vision</b><br>
                        Tetsunari Inamura<br>
                        @ National Institute of Informatics, Tokyo, Japan
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/flowers.png" height="32"/>
                    </td>
                    <td>
                        <b>2014</b><br>
                        <b>Multimodal concepts emergence for a humanoid robot in interaction with a human tutor</b><br>
                        David Filliat<br>
                        @ Flowers laboratory, Inria and ENSTA ParisTech, Paris, France<br>
                        <a href=https://youtu.be/Ym5aYfzoQX8>Video</a> and
                        <a href=https://youtu.be/i8xQaVQDfBQ>video</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/inria.png" height="30"/>
                    </td>
                    <td>
                        <b>2013</b><br>
                        <b>Optimal decision making based on a mixture of prediction experts</b><br>
                        <b>Homeostatic engine for reinforcement learning agents</b><br>
                        Laurent Orseau<br>
                        @ Inria and AgroParisTech, Paris, France
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/lip6.png" height="50"/>
                    </td>
                    <td>
                        <b>2013</b><br>
                        <b>Ontology visualization methods and their impact on short-term memory storage in humans</b><br>
                        Jean-Gabriel Ganascia<br>
                        @ Lip6, Paris, France
                    </td>
                </tr>
            </table>
        </div>

        <div>
            <h2>Publications</h2>
            <table>
                <tr>
                    <td width="350">
                        <img src="images/comic.gif" height="100"/>
                    </td>
                    <td>
                        <b>CoMic: Complementary Task Learning & Mimicry for Reusable Skills</b><br>
                        Leonard Hasenclever, Fabio Pardo, Raia Hadsell, Nicolas Heess, Josh Merel<br>
                        @ ICML 2020<br>
                        <a href="https://proceedings.icml.cc/static/paper_files/icml/2020/5013-Paper.pdf">Paper</a> and
                        <a href="https://github.com/deepmind/dm_control/tree/master/dm_control/locomotion/tasks/reference_pose">code</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/qmap_mario_montezuma.gif" height="200"/>
                    </td>
                    <td>
                        <b>Scaling All-Goals Updates in Reinforcement Learning Using Convolutional Neural Networks</b><br>
                        Fabio Pardo, Vitaly Levdik, Petar Kormushev<br>
                        @ AAAI 2020<br>
                        @ NeurIPS 2018 Deep RL Workshop<br>
                        @ ICML 2018 Exploration in RL Workshop<br>
                        <a href="https://arxiv.org/abs/1810.02927">Paper</a>,
                        <a href="posters/qmap.pdf">poster</a>,
                        <a href="https://sites.google.com/view/q-map-rl">website</a> and
                        <a href="https://github.com/fabiopardo/qmap">code</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/time-limited_Hopper.gif" height="100"/>
                        <img src="images/time-unlimited_Hopper.gif" height="100"/>
                    </td>
                    <td>
                        <b>Time Limits in Reinforcement Learning</b><br>
                        Fabio Pardo, Arash Tavakoli, Vitaly Levdik, Petar Kormushev<br>
                        @ ICML 2018<br>
                        @ NIPS 2017 Deep RL Symposium<br>
                        <a href="https://arxiv.org/abs/1712.00378">Paper</a>,
                        <a href="posters/time_limits_in_rl.pdf">poster</a> and
                        <a href="https://sites.google.com/view/time-limits-in-rl">website</a>
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/branching.png" height="80"/>
                    </td>
                    <td>
                        <b>Action Branching Architectures for Deep Reinforcement Learning</b><br>
                        Arash Tavakoli, Fabio Pardo, Petar Kormushev<br>
                        @ AAAI 2018<br>
                        @ NIPS 2017 Deep RL Symposium<br>
                        <a href="https://arxiv.org/abs/1711.08946">Paper</a> and
                        <a href="posters/action_branching_architectures.pdf">poster</a>
                    </td>
                </tr>
            </table>
        </div>

        <div>
            <h2>Softwares</h2>
            <table>
                <tr>
                    <td width="350">
                        <img src="images/tonic.png" height="70"/><br><br>
                        <img src="images/tonic.gif" height="100"/>
                    </td>
                    <td>
                        <b>Tonic: A Deep Reinforcement Learning Library for Fast Prototyping and Benchmarking</b><br>
                        <ul>
                            <li>a collection of configurable modules such as: exploration strategies, memories, neural networks, and optimizers</li>
                            <li>a collection of baseline agents built with these modules</li>
                            <li>support for the two most popular deep learning frameworks: TensorFlow and PyTorch</li>
                            <li>support for the three most popular sets of continuous control environments: OpenAI Gym, DeepMind Control Suite and PyBullet</li>
                            <li>a large-scale benchmark of the baseline agents on 70 tasks</li>
                            <li>scripts to train in a reproducible way, plot results, and play with trained agents.</li>
                        </ul>
                        <a href="https://github.com/fabiopardo/tonic">Repository</a> and
                        <a href="https://github.com/fabiopardo/tonic_data">data</a>
                    </td>
                </tr>
            </table>
        </div>

        <div>
            <h2>Miscellaneous</h2>
            <table>
                <tr>
                    <td width="350">
                        <img src="images/imperial.png" height="50"/>
                    </td>
                    <td>
                        <b>2018 – present</b><br>
                        <b>Organizer of Imperial's deep reinforcement learning reading group</b><br>
                        Weekly meetings to discuss papers (contact me if you want to join)<br>
                        @ Imperial College, London, UK
                    </td>
                </tr>
                <tr>
                    <td width="350">
                        <img src="images/imperial.png" height="50"/>
                    </td>
                    <td>
                        <b>2016 – 2018</b><br>
                        <b>Graduate teaching assistant in Computing and Robotics</b><br>
                        Lectures, tutorials, exams<br>
                        @ Imperial College, London, UK
                    </td>
                </tr>
                <tr>
                    <td>
                        <img src="images/prologin.png" height="60"/>
                    </td>
                    <td>
                        <b>2011 and 2012</b><br>
                        <b>Twice finalist of Prologin, the French national programming contest</b><br>
                        Algorithmic tests and 36-hour hackathon<br>
                        @ École Polytechnique and EPITA, Paris, France
                    </td>
                </tr>
            </table>
        </div>
    </body>
</html>
